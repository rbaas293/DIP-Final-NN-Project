{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Things\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Import Stuff Created In This Section:\\n\\n    data_root: a Path variable describing where a shit load of jpg images are stored\\n    all_image_paths: a list of paths that refer to a shit load of jpg images\\n    all_image_labels: a list of the categories that correspond to each of the images in all_image_paths\\n    my_attributions: a dictionary of things that describe the jpg images\\n    label_to_index: a dictionary of possible categories for these images\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enable eager ... cant do this with nightly builds for -gpu ... also must have version 10.0 of cuda toolkit\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "#################################################################################\n",
    "#################### DOWLOAD A SET OF JPG IMAGES ################################\n",
    "#################################################################################\n",
    "\"\"\"Import Stuff Created In This Section:\n",
    "\n",
    "    data_root: a Path variable describing where a shit load of jpg images are stored\n",
    "    all_image_paths: a list of paths that refer to a shit load of jpg images\n",
    "    all_image_labels: a list of the categories that correspond to each of the images in all_image_paths\n",
    "    my_attributions: a dictionary of things that describe the jpg images\n",
    "    label_to_index: a dictionary of possible categories for these images\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the file\n",
    "data_root_orig = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    fname='flower_photos', untar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPG images downloaded to the following location:  C:\\Users\\Baas Mane\\.keras\\datasets\\flower_photos\n"
     ]
    }
   ],
   "source": [
    "#save the path where the files were saved\n",
    "data_root = pathlib.Path(data_root_orig)\n",
    "print(\"JPG images downloaded to the following location: \", data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a list of all the files we just downloaded\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the list of jpg paths\n",
    "random.shuffle(all_image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This function parses out a caption for an image given its path and the overall attribtuions dict'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process the LICENSE.txt file, which contains all the info we need to know about the images.\n",
    "my_attributions = (data_root / \"LICENSE.txt\").open(encoding='utf-8').readlines()[4:]\n",
    "my_attributions = [line.split(' CC-BY') for line in my_attributions]\n",
    "my_attributions = dict(my_attributions)\n",
    "\n",
    "\"\"\"This function parses out a caption for an image given its path and the overall attribtuions dict\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run it\n",
    "def caption_image(image_path, attributions):\n",
    "    # added as_posix() to this line, because windows path doesn't match LICENSE.txt format.\n",
    "    image_rel = pathlib.Path(image_path).relative_to(data_root).as_posix()\n",
    "    return \"Image (CC BY 2.0) \" + ' - '.join(attributions[str(image_rel)].split(' - ')[:-1])\n",
    "\n",
    "\n",
    "# #\n",
    "# # for n in range(3):\n",
    "# #   image_path = random.choice(all_image_paths)\n",
    "# #   display.display(display.Image(image_path))\n",
    "# #   print(caption_image(image_path))\n",
    "# #   print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label_to_index dict is:  {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n"
     ]
    }
   ],
   "source": [
    "#determine the text for image label possibilities, then assign numbers to those options in a dict\n",
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "print(\"The label_to_index dict is: \", label_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Import Stuff Created In This Section:\\n\\n    watermarked_root: a Path variable describing where a shit load of WATERMARKED jpg images are stored\\n    all_watermarked_paths: a list of paths that refer to a shit load of WATERMARKED jpg images\\n    \\n    The following variables still correspond to all_watermarked_paths:\\n    all_image_labels: a list of the categories that correspond to each of the images in all_image_paths\\n    my_attributions: a dictionary of things that describe the jpg images\\n    label_to_index: a dictionary of possible categories for these images\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a list of each images label, corresponding to all_image_paths\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n",
    "#################################################################################\n",
    "#################### GENERATE A SET OF WATERMARKED IMAGES #######################\n",
    "#################################################################################\n",
    "\"\"\"Import Stuff Created In This Section:\n",
    "\n",
    "    watermarked_root: a Path variable describing where a shit load of WATERMARKED jpg images are stored\n",
    "    all_watermarked_paths: a list of paths that refer to a shit load of WATERMARKED jpg images\n",
    "    \n",
    "    The following variables still correspond to all_watermarked_paths:\n",
    "    all_image_labels: a list of the categories that correspond to each of the images in all_image_paths\n",
    "    my_attributions: a dictionary of things that describe the jpg images\n",
    "    label_to_index: a dictionary of possible categories for these images\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import watermaking paths to variables\n",
    "pwd = os.path.abspath('') + \"//\" # Dont know why I thought that wouldnt work in the first place lol\n",
    "FONT_PATH = pwd + \"current_test_data//BERNHC.TTF\"\n",
    "WATERMARK_TEXT = \"SHEETZ | BAAS | OHM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Watermark a picture!\n",
    "def watermark_text(input_image_path, output_image_path, text, pos):\n",
    "    photo = Image.open(input_image_path)\n",
    "\n",
    "    # make the image editable\n",
    "    drawing = ImageDraw.Draw(photo)\n",
    "\n",
    "    black = (3, 8, 12)\n",
    "    font = ImageFont.truetype(FONT_PATH, size=50)\n",
    "    drawing.text(pos, text, fill=black, font=font)\n",
    "    # photo.show()\n",
    "    photo.save(output_image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new directory path string to house the watermarked images (does not actually create the dir)\n",
    "watermarked_root = data_root.with_name(str(data_root.name)+\"_watermarked\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Watermarked Directory....\n"
     ]
    }
   ],
   "source": [
    "#makes a blank list for strings indicating paths to watermarked photos, in the same order as all_image_paths\n",
    "all_watermarked_paths = []\n",
    "\n",
    "print(\"Creating Watermarked Directory....\")\n",
    "for img_path in all_image_paths:\n",
    "    p = pathlib.Path(img_path)\n",
    "    output_path = watermarked_root/p.parent.name/p.name\n",
    "    # watermark_text(\n",
    "        # img_path,\n",
    "        # output_path,\n",
    "        # text=WATERMARK_TEXT,\n",
    "        # pos=(0, 0)\n",
    "    # )\n",
    "    all_watermarked_paths += [str(output_path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#################### CONVERT FROM JPG TO DATASET ################################\n",
    "#################################################################################\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img_raw = tf.io.read_file(img_path)\n",
    "    img_tensor=preprocess_image(img_raw)\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [192,192])\n",
    "    image /= 255.0\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below unpacks The tuples into the positional arguments of the mapped function\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "  return load_and_preprocess_image(path), label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set counter to zero and build from the list baby!\n",
    "counter = 0\n",
    "\n",
    "def build_from_list(paths, labels, counter):\n",
    "    # Build a tf.data.Dataset\n",
    "\n",
    "    print(\"\\n\\nBuilding A Dataset...\", counter)\n",
    "    counter = counter+1\n",
    "\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "    print(image_label_ds)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    # Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "    # completely shuffled.\n",
    "    ds = image_label_ds.shuffle(buffer_size=len(paths))\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    # `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    ds = image_label_ds.apply(\n",
    "      tf.data.experimental.shuffle_and_repeat(buffer_size=len(labels)))\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    print(ds)\n",
    "\n",
    "    # The dataset may take a few seconds to start, as it fills its shuffle buffer.\n",
    "    image_batch, label_batch = next(iter(ds))\n",
    "\n",
    "    return image_batch, label_batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train thing setup 1\n",
    "train_og_paths = all_image_paths[:5]\n",
    "train_og_labels = all_image_labels[:5]\n",
    "test_og_paths = all_image_paths[5:]\n",
    "test_og_labels = all_image_labels[5:]\n",
    "train_wm_paths = all_watermarked_paths[:5]\n",
    "train_wm_labels = all_image_labels[:5]\n",
    "test_wm_paths = all_watermarked_paths[5:]\n",
    "test_wm_labels = all_image_labels[5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building A Dataset... 0\n",
      "<DatasetV1Adapter shapes: ((192, 192, 3), ()), types: (tf.float32, tf.int32)>\n",
      "<DatasetV1Adapter shapes: ((?, 192, 192, 3), (?,)), types: (tf.float32, tf.int32)>\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Train thing setup 2\n",
    "train_og_image_batch, train_og_label_batch = build_from_list(\n",
    "    train_og_paths, train_og_labels, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building A Dataset... 0\n",
      "<DatasetV1Adapter shapes: ((192, 192, 3), ()), types: (tf.float32, tf.int32)>\n",
      "<DatasetV1Adapter shapes: ((?, 192, 192, 3), (?,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# Train thing setup 3\n",
    "test_og_image_batch, test_og_label_batch = build_from_list(\n",
    "    test_og_paths, test_og_labels, counter)\n",
    "\n",
    "#train_wm_image_batch, train_wm_label_batch = build_from_list(\n",
    "#   train_wm_paths, train_wm_labels, counter)\n",
    "\n",
    "#test_wm_image_batch, test_wm_label_batch = build_from_list(\n",
    "#    test_wm_paths, test_wm_labels, counter)\n",
    "\n",
    "#################################################################################\n",
    "################### END OF FILE #################################################\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DEBUG 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Scale the 0-255 values down to 0-1 before feeding them to the model\n",
    "print(\"\\n\\n DEBUG 1\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DEBUG 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build the model -- setup the layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(192, 192, 3)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "print(\"\\n\\n DEBUG 2\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DEBUG 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build the model -- compile the model!!\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"\\n\\n DEBUG 3\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d4b3bf84ff1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Train the Model Finally!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_og_image_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_og_label_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#######################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[0mvar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m    818\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 820\u001b[1;33m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  11326\u001b[0m         \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11327\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"new_axis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shrink_axis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11328\u001b[1;33m         shrink_axis_mask)\n\u001b[0m\u001b[0;32m  11329\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11330\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "#Train the Model Finally!!!\n",
    "model.fit(train_og_image_batch, train_og_label_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#######################################\n",
    "########## TEST MODEL #################\n",
    "#######################################\n",
    "\n",
    "\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(test_og_image_batch, test_og_label_batch)\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
